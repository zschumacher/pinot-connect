{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"pinot-connect","text":"pippoetryuv <pre><code>pip install pinot-connect\n</code></pre> <pre><code>poetry add pinot-connect\n</code></pre> <pre><code>uv add pinot-connect\n</code></pre> <p>pinot_connect is a DB-API 2.0 compliant and statically typed driver for querying Apache Pinot with  Python. It supports both synchronous and asynchronous execution, making it flexible for a variety of  applications.</p> <p>Powered by:</p> <ul> <li>orjson for high-performance JSON deserialization</li> <li>httpx for async support and connection pooling</li> </ul> <p><code>pinot_connect</code> outperforms <code>pinotdb</code> in benchmarks.  On average for queries that return 100 or more rows, you can  expect to see ~15-30% faster execution. </p> <p>Check out the benchmarks for more details.</p>"},{"location":"#running-a-quick-start-pinot-cluster","title":"Running a quick start Pinot cluster","text":"<p>To start an Apache Pinot cluster with example data, run: <pre><code>docker run -d --name pinot-quickstart -p 9000:9000 \\\n  -p 8099:8000 \\\n  --health-cmd=\"curl -f http://localhost:9000/health || exit 1\" \\\n  --health-interval=10s \\\n  --health-timeout=5s \\\n  --health-retries=5 \\\n  --health-start-period=10s \\\n  apachepinot/pinot:latest QuickStart -type batch\n</code></pre> This command launches a Pinot instance with preloaded batch data, making it easy to start querying right away.</p>"},{"location":"#querying-with-pinot_connect","title":"Querying with pinot_connect","text":"<p>Once your cluster is up and running, you can query it using pinot_connect. Below are examples for both synchronous and  asynchronous usage.</p> <p>Example</p> syncasync <pre><code>import pinot_connect\nfrom pinot_connect.rows import dict_row\n\nwith pinot_connect.connect(host=\"localhost\") as conn:\n    with conn.cursor(row_factory=dict_row) as cursor:\n        cursor.execute(\"select * from airlineStats limit 100\")\n        for row in cursor:\n            print(row)\n</code></pre> <pre><code>import pinot_connect\nfrom pinot_connect.rows import dict_row\nimport asyncio\n\nasync def main():\n    async with pinot_connect.AsyncConnection.connect(hose=\"localhost\") as conn:\n        async with conn.cursor(row_factory=dict_row) as cursor:\n            await cursor.execute(\"select * from airlineStats limit 100\")\n            async for row in cursor:\n                print(row)\n\nasyncio.run(main())\n</code></pre> <p>What's Happening Here?</p> <ul> <li> <p>Standard DB-API 2.0 Interface <code>pinot_connect</code> provides a familiar connection and cursor interface, similar to popular Python database clients such as   <code>sqlite3</code> or <code>psycopg</code></p> </li> <li> <p>Row Factories   The <code>row_factory</code> parameter lets you customize how rows are returned. In this example, <code>dict_row</code> returns results as   dictionaries. You can choose from built-in factories or define your own. See the    row factories documentation for details.</p> </li> <li> <p>Type Mapping <code>pinot_connect</code> automatically converts Pinot data types to their Python equivalents.</p> </li> <li> <p>Cursor Iteration &amp; Fetch Methods   You can iterate over results directly or use <code>fetchone()</code>, <code>fetchmany()</code>, <code>fetchall()</code>, and <code>scroll()</code>, following the    DB-API spec. See the usage docs or reference docs for more details.</p> </li> </ul>"},{"location":"benchmarks/","title":"Benchmarks","text":"<p>Benchmarks were performed using a pinot quickstart batch cluster and the <code>githubComplexTypeEvents</code> table. All times for benchmarks are recorded in milliseconds.  These benchmarks compare <code>pinot_connect</code> performance to <code>pinotdb</code> performance.</p>"},{"location":"benchmarks/#running-benchmarks","title":"Running benchmarks","text":"<p>To run the benchmarks yourself, start the quickstart cluster referenced on the homepage.  Then run: <pre><code>git clone git@github.com:zschumacher/pydapper.git\ncd pydapper\nasdf install\npoetry install\npoetry run python scripts/pinotdb_benchmarks.py \n</code></pre></p> <p>Note</p> <p><code>pinotdb</code> returns rows untouched as a list of lists, so the benchmark for <code>pinot_connect</code> uses a <code>list_row</code> factory to mirror that behavior in all benchmarks.  Additionally, python garbage collection is disabled for all benchmarks.</p>"},{"location":"benchmarks/#large-query","title":"Large query","text":"<pre><code>select * from githubComplexTypeEvents limit 1000\n</code></pre> <p>Note</p> <p>Large queries see a much larger performance improvement mostly due to faster json deserialization via <code>orjson</code>.  The  larger the query result becomes, the better pinot_connect will perform when compared to pinotdb.</p>"},{"location":"benchmarks/#sync","title":"Sync","text":"<p>Run the query 100 times sequentially</p> fetchonefetchmanyfetchall total avg median p95 pinot_connect 3211.60 32.12 31.80 34.24 pinotdb 3820.82 38.21 38.08 39.46 diff% 18.97% 18.97% 19.75% 15.24% total avg median p95 pinot_connect 3278.68 32.79 32.54 34.92 pinotdb 3898.60 38.99 38.99 40.55 diff% 18.91% 18.91% 19.82% 16.12% total avg median p95 pinot_connect 3278.01 32.78 32.66 34.18 pinotdb 3908.55 39.09 39.16 40.42 diff% 19.24% 19.24% 19.91% 18.26%"},{"location":"benchmarks/#async","title":"Async","text":"<p>Run the query 100 times concurrently</p> fetchonefetchmanyfetchall total pinot_connect 1737.41 pinotdb 2278.16 diff% 31.12% total pinot_connect 1805.03 pinotdb 2359.02 diff% 30.69% total pinot_connect 1843.05 pinotdb 2372.22 diff% 28.71%"},{"location":"benchmarks/#small-query","title":"Small query","text":"<pre><code>select * from githubComplexTypeEvents limit 10\n</code></pre> <p>Note</p> <p>Smaller query results see less of a performance difference - the effects from <code>orjson</code> are diminished and the small improvements are due to the slightly more efficient cursor in <code>pinot_connect</code></p>"},{"location":"benchmarks/#sync_1","title":"Sync","text":"<p>Run the query 1000 times sequentially</p> fetchonefetchmanyfetchall total avg median p95 pinot_connect 3669.85 3.67 3.62 4.51 pinotdb 3879.03 3.88 3.83 4.67 diff% 5.70% 5.70% 5.83% 3.70% total avg median p95 pinot_connect 3721.37 3.72 3.70 4.43 pinotdb 3896.81 3.90 3.81 4.80 diff% 4.71% 4.71% 3.04% 8.41% total avg median p95 pinot_connect 3660.49 3.66 3.59 4.55 pinotdb 3886.63 3.89 3.80 4.59 diff% 6.18% 6.18% 5.72% 0.92%"},{"location":"benchmarks/#async_1","title":"Async","text":"<p>Run the query 1000 times concurrently</p> fetchonefetchmanyfetchall total pinot_connect 3364.68 pinotdb 3405.71 diff% 1.22% total pinot_connect 3256.76 pinotdb 3306.85 diff% 1.54% total pinot_connect 3325.85 pinotdb 3379.53 diff% 1.61%"},{"location":"release_notes/","title":"Release Notes","text":""},{"location":"release_notes/#latest-changes","title":"Latest Changes","text":""},{"location":"release_notes/#011","title":"0.1.1","text":""},{"location":"release_notes/#features","title":"Features","text":"<ul> <li>feat: check for servers queried and expose query statistics. PR #6 by @zschumacher.</li> </ul>"},{"location":"release_notes/#010","title":"0.1.0","text":"<p>Initial release of <code>pinot-connect</code></p>"},{"location":"reference/","title":"Reference","text":"<p>Reference docs for the classes, functions, parameters, attributes, and all the <code>pinot_connect</code> components you can use in your  applications.</p>"},{"location":"reference/connection/","title":"pinot_connect.connection","text":""},{"location":"reference/connection/#pinot_connectconnection","title":"pinot_connect.connection","text":""},{"location":"reference/connection/#baseconnection","title":"BaseConnection","text":"<pre><code>class BaseConnection(t.Generic[_CursorType, _ClientType])\n</code></pre>"},{"location":"reference/connection/#__init__","title":"__init__","text":"<pre><code>def __init__(client: _ClientType,\n             *,\n             query_options: QueryOptions | None = None)\n</code></pre> <p>Base class for building connections to Apache Pinot</p> <p>Arguments:</p> <ul> <li><code>client</code> - an instance of subclass of httpx.Client</li> <li><code>query_options</code> - (optional): global query options for all queries made from the connection</li> </ul> <p></p>"},{"location":"reference/connection/#closed","title":"closed","text":"<pre><code>@property\ndef closed() -&gt; bool\n</code></pre> <p><code>True</code> if connection's client is closed</p> <p></p>"},{"location":"reference/connection/#connection","title":"Connection","text":"<pre><code>class Connection(BaseConnection[Cursor, httpx.Client])\n</code></pre>"},{"location":"reference/connection/#connect","title":"connect","text":"<pre><code>@classmethod\ndef connect(cls,\n            host: str,\n            port: int = 8099,\n            username: str | None = None,\n            password: str | None = None,\n            scheme: t.Literal[\"http\", \"https\"] = \"http\",\n            database: str | None = None,\n            query_options: QueryOptions | None = None,\n            client_options: ClientOptions | None = None) -&gt; Self\n</code></pre> <p>Constructor for building a client and returning a connection</p> <p>Arguments:</p> <ul> <li><code>host</code> - the hostname of your apache pinot broker</li> <li><code>port</code> - (optional) the port of your apache pinot broker, defaults to <code>8099</code></li> <li><code>username</code> - (optional): the username to use, if auth is enabled</li> <li><code>password</code> - (optional): the password to use, if auth is enabled</li> <li><code>scheme</code> - (optional): the scheme to use, defaults to <code>http</code></li> <li><code>database</code> - (optional): the database/tenant to use</li> <li><code>query_options</code> - (optional): global query options for all queries made from the connection</li> <li><code>client_options</code> - (optional): httpx client options for all queries made from the connection</li> </ul> <p></p>"},{"location":"reference/connection/#cursor","title":"cursor","text":"<pre><code>def cursor(*,\n           query_options: QueryOptions | None = None,\n           row_factory=tuple_row)\n</code></pre> <p>Builds a new pinot_connect.Cursor object using the connection.</p> <p>Arguments:</p> <ul> <li><code>query_options</code> - (optional): query options to be used by cursor, overrides any options set at connection level</li> <li><code>row_factory</code> - (optional): RowFactory type to use to build rows fetched from cursor, defaults to returning   tuples</li> </ul> <p></p>"},{"location":"reference/connection/#close","title":"close","text":"<pre><code>def close()\n</code></pre> <p>Close the connection and cleans up resources.</p> <p>Closes all open cursors and all open TCP connections in the client.</p> <p></p>"},{"location":"reference/connection/#asyncconnection","title":"AsyncConnection","text":"<pre><code>class AsyncConnection(BaseConnection[AsyncCursor, httpx.AsyncClient])\n</code></pre>"},{"location":"reference/connection/#connect_1","title":"connect","text":"<pre><code>@classmethod\ndef connect(\n        cls,\n        host: str,\n        port: int = 8099,\n        username: str | None = None,\n        password: str | None = None,\n        scheme: t.Literal[\"http\", \"https\"] = \"http\",\n        database: str | None = None,\n        query_options: QueryOptions | None = None,\n        client_options: ClientOptions | None = None\n) -&gt; CoroContextManager[Self]\n</code></pre> <p>Constructor for building a client and returning an async connection wrapped in a CoroContextManager object.  This allows this method to both be awaited and be used with async with (without having to do async with await).</p> <p>Arguments:</p> <ul> <li><code>host</code> - the hostname of your apache pinot broker</li> <li><code>port</code> - the port of your apache pinot broker, defaults to <code>8099</code></li> <li><code>username</code> - (optional): the username to use, if auth is enabled</li> <li><code>password</code> - (optional): the password to use, if auth is enabled</li> <li><code>scheme</code> - (optional): the scheme to use, defaults to <code>http</code></li> <li><code>database</code> - (optional): the database/tenant to use</li> <li><code>query_options</code> - (optional): global query options for all queries made from the connection</li> <li> <p><code>client_options</code> - (optional): httpx client options for all queries made from the connection</p> </li> <li> <p><code>Returns</code> - an instance of <code>pinot_connect.AsyncConnection</code> wrapped in a CoroContextManager</p> </li> </ul> <p></p>"},{"location":"reference/connection/#commit","title":"commit","text":"<pre><code>async def commit()\n</code></pre> <p>Not implemented - read only interface</p> <p></p>"},{"location":"reference/connection/#cursor_1","title":"cursor","text":"<pre><code>def cursor(query_options: QueryOptions | None = None, row_factory=tuple_row)\n</code></pre> <p>Builds a new pinot_connect.AsyncCursor object using the connection.</p> <p>Arguments:</p> <ul> <li><code>query_options</code> - (optional): query options to be used by cursor, overrides any options set at connection level</li> <li><code>row_factory</code> - (optional): RowFactory type to use to build rows fetched from cursor, defaults to returning   tuples</li> </ul> <p></p>"},{"location":"reference/connection/#close_1","title":"close","text":"<pre><code>async def close()\n</code></pre> <p>Close the connection and cleans up resources.</p> <p>Closes all open cursors and all open TCP connections in the client.</p>"},{"location":"reference/context/","title":"pinot_connect.context","text":""},{"location":"reference/context/#pinot_connectcontext","title":"pinot_connect.context","text":""},{"location":"reference/context/#corocontextmanager","title":"CoroContextManager","text":"<pre><code>class CoroContextManager(t.Coroutine[t.Any, t.Any, _TObj], t.Generic[_TObj])\n</code></pre> <p>Simple object that allows an async function to be awaited directly or called using <code>async with func(...)</code>.</p> <p>Prevents having to write <code>async with await func(...)</code></p>"},{"location":"reference/cursor/","title":"pinot_connect.cursor","text":""},{"location":"reference/cursor/#pinot_connectcursor","title":"pinot_connect.cursor","text":""},{"location":"reference/cursor/#querystatistics","title":"QueryStatistics","text":"<pre><code>class QueryStatistics(t.TypedDict)\n</code></pre> <p>TypedDict for exposing query statistics for the last executed query</p> <p>This exposes relevant statistics and metrics from the query execution reported by the Pinot broker, including server-side performance, pruning details, and total rows/documents processed.</p> <p>Attributes:</p> <ul> <li><code>brokerId</code> - The ID of the broker that executed this query.</li> <li><code>brokerReduceTimeMs</code> - The time taken by the broker to reduce the results from servers, expressed in milliseconds.</li> <li><code>explainPlanNumEmptyFilterSegments</code> - Number of segments skipped due to empty filter matches in the explain plan.</li> <li><code>explainPlanNumMatchAllFilterSegments</code> - Number of segments where all rows matched due to 'match-all' filter in the explain plan.</li> <li><code>maxRowsInJoinReached</code> - Indicates if the query processing hit the maximum number of rows allowed in a join operation.</li> <li><code>maxRowsInOperator</code> - The maximum number of rows processed by any operator during query execution.</li> <li><code>maxRowsInWindowReached</code> - Indicates if the maximum number of rows were hit in any window function during execution.</li> <li><code>minConsumingFreshnessTimeMs</code> - The minimum freshness time in milliseconds of consuming (real-time) segments.</li> <li><code>numConsumingSegmentsMatched</code> - The number of consuming (real-time) segments that matched the query criteria.</li> <li><code>numConsumingSegmentsProcessed</code> - The number of consuming (real-time) segments that were processed during query execution.</li> <li><code>numConsumingSegmentsQueried</code> - The number of consuming (real-time) segments queried during the execution.</li> <li><code>numDocsScanned</code> - The total number of documents (rows) scanned in the query.</li> <li><code>numEntriesScannedInFilter</code> - The total number of entries scanned by filter operations during the query.</li> <li><code>numEntriesScannedPostFilter</code> - The total number of entries scanned after applying filter operations.</li> <li><code>numGroupsLimitReached</code> - Indicates if the limit on the number of groups in the GROUP BY clause was reached.</li> <li><code>numRowsResultSet</code> - The total number of rows returned in the query result set.</li> <li><code>numSegmentsMatched</code> - The total number of segments that matched the query criteria.</li> <li><code>numSegmentsProcessed</code> - The total number of segments processed by the servers during query processing.</li> <li><code>numSegmentsPrunedByBroker</code> - The number of segments that were pruned (skipped) by the broker.</li> <li><code>numSegmentsPrunedByLimit</code> - The number of segments pruned due to query limits (e.g., TOP N queries).</li> <li><code>numSegmentsPrunedByServer</code> - The number of segments pruned by the servers during query execution.</li> <li><code>numSegmentsPrunedByValue</code> - The number of segments pruned based on the value range (e.g., partitioning or pruning on primary keys).</li> <li><code>numSegmentsPrunedInvalid</code> - The number of invalid or unnecessary segments pruned by the broker or server.</li> <li><code>numSegmentsQueried</code> - The number of segments queried during the execution.</li> <li><code>numServersQueried</code> - The number of servers queried by the broker for this request.</li> <li><code>numServersResponded</code> - The number of servers that successfully responded with query results.</li> <li><code>offlineResponseSerializationCpuTimeNs</code> - CPU time spent in serializing offline segment responses, in nanoseconds.</li> <li><code>offlineSystemActivitiesCpuTimeNs</code> - Total CPU time spent in system activities related to offline segments, in nanoseconds.</li> <li><code>offlineThreadCpuTimeNs</code> - Total thread CPU time spent in processing offline segments, in nanoseconds.</li> <li><code>offlineTotalCpuTimeNs</code> - Total CPU time including query processing for offline segments, in nanoseconds.</li> <li><code>partialResult</code> - Indicates if the result is partial (e.g., due to query timeouts or server issues).</li> <li><code>realtimeResponseSerializationCpuTimeNs</code> - CPU time spent serializing real-time segment responses, in nanoseconds.</li> <li><code>realtimeSystemActivitiesCpuTimeNs</code> - Total CPU time spent in system activities for real-time segments, in nanoseconds.</li> <li><code>realtimeThreadCpuTimeNs</code> - Total thread CPU time spent in processing real-time segments, in nanoseconds.</li> <li><code>realtimeTotalCpuTimeNs</code> - Total CPU time including query processing for real-time segments, in nanoseconds.</li> <li><code>requestId</code> - The unique identifier for the query request.</li> <li><code>segmentStatistics</code> - A list of segment-level statistics for query execution.</li> <li><code>stageStats</code> - A dictionary containing stage-specific statistics for multi-stage queries.</li> <li><code>stateStats</code> - A dictionary containing state-specific statistics for query execution.</li> <li><code>tablesQueried</code> - A list of table names that were queried.</li> <li><code>timeUsedMs</code> - The total time taken to execute the query, in milliseconds.</li> <li><code>totalDocs</code> - The total number of documents in the queried segments.</li> <li><code>traceInfo</code> - A dictionary containing tracing information for the query execution.</li> </ul> <p></p>"},{"location":"reference/cursor/#basecursor","title":"BaseCursor","text":"<pre><code>class BaseCursor(t.Generic[_ConnectionType, RowType])\n</code></pre>"},{"location":"reference/cursor/#description","title":"description","text":"<pre><code>@property\ndef description() -&gt; list[Column] | None\n</code></pre> <p>Description of query result</p> <p>Only name and type code (index 0 and 1) will ever be populated for this implementation</p> <p></p>"},{"location":"reference/cursor/#connection","title":"connection","text":"<pre><code>@property\ndef connection() -&gt; _ConnectionType\n</code></pre> <p>Pointer to the connection used to create this cursor</p> <p></p>"},{"location":"reference/cursor/#rownumber","title":"rownumber","text":"<pre><code>@property\ndef rownumber() -&gt; int | None\n</code></pre> <p>Current position of cursor</p> <p></p>"},{"location":"reference/cursor/#rowcount","title":"rowcount","text":"<pre><code>@property\ndef rowcount() -&gt; int | None\n</code></pre> <p>Number of rows returned by last executed query</p> <p></p>"},{"location":"reference/cursor/#closed","title":"closed","text":"<pre><code>@property\ndef closed() -&gt; bool\n</code></pre> <p><code>True</code> if the cursor is closed</p> <p></p>"},{"location":"reference/cursor/#arraysize","title":"arraysize","text":"<pre><code>@property\ndef arraysize() -&gt; int\n</code></pre> <p>Number of rows to fetch with fetchmany if no size is specified in the method call</p> <p></p>"},{"location":"reference/cursor/#query","title":"query","text":"<pre><code>@property\ndef query() -&gt; str | None\n</code></pre> <p>Last executed query</p> <p></p>"},{"location":"reference/cursor/#query_statistics","title":"query_statistics","text":"<pre><code>@property\ndef query_statistics() -&gt; QueryStatistics | None\n</code></pre> <p>Statistics about the last executed query</p> <p></p>"},{"location":"reference/cursor/#mogrify","title":"mogrify","text":"<pre><code>def mogrify(operation: str, params: dict | tuple | list | None = None) -&gt; str\n</code></pre> <p>Take an operation and params and return the operation after param binding</p> <p></p>"},{"location":"reference/cursor/#cursor","title":"Cursor","text":"<pre><code>class Cursor(BaseCursor[\"Connection\", RowType])\n</code></pre>"},{"location":"reference/cursor/#scroll","title":"scroll","text":"<pre><code>@check_cursor_open\ndef scroll(value: int,\n           *,\n           mode: t.Literal[\"relative\", \"absolute\"] = \"relative\") -&gt; None\n</code></pre> <p>Move the cursor in the result set to a new position using the mode.</p> <p>If mode=<code>relative</code> (default), treat the passed value as an offset relative to the current position in the result set. If mode=<code>absolute</code>, move to the passed position.</p> <p>Arguments:</p> <ul> <li><code>value</code> - The offset if in <code>relative</code> mode; the target position if in <code>absolute</code> mode</li> <li><code>mode</code> - (optional) determines the model to use for the scroll.  Default: <code>relative</code></li> </ul> <p></p>"},{"location":"reference/cursor/#execute","title":"execute","text":"<pre><code>@check_cursor_open\ndef execute(operation: str,\n            params: dict | tuple | list | None = None,\n            *,\n            query_options: QueryOptions | None = None,\n            request_options: RequestOptions | None = None) -&gt; httpx.Response\n</code></pre> <p>Execute a query against the Pinot broker</p> <p>The query returns the <code>httpx.Response</code> from the request, which you normally will not need; however, it may be useful for debugging.</p> <p>Arguments:</p> <ul> <li><code>operation</code> - the sql operation to send to the broker</li> <li><code>params</code> - (optional) sql params to bind to the operation</li> <li><code>query_options</code> - (optional) query options that override what is set on cursor/connection</li> <li><code>request_options</code> - (optional) request options to use for this specific query.  Can override timeout and   cookies from cursor/connection</li> </ul> <p></p>"},{"location":"reference/cursor/#fetchone","title":"fetchone","text":"<pre><code>@check_cursor_open\ndef fetchone() -&gt; RowType | None\n</code></pre> <p>Fetch the next record from the current result set or <code>None</code> if exhausted</p> <p>uses passed <code>row_factory</code> to cursor to determine <code>RowType</code> of returned row</p> <p></p>"},{"location":"reference/cursor/#fetchmany","title":"fetchmany","text":"<pre><code>@check_cursor_open\ndef fetchmany(size: int | None = None) -&gt; list[RowType]\n</code></pre> <p>Fetch the next size records from the current result set.  If size is not passed, the value of the <code>arraysize</code> property will be used instead.</p> <p>Uses passed <code>row_factory</code> to cursor to determine <code>RowType</code> of returned rows.</p> <p>This method can return fewer records than requested.  For example, if a size of 3 is passed, but the result set only has two records remaining, the two records will be returned only.</p> <p>Arguments:</p> <ul> <li><code>size</code> - (optional) number of records to fetch - if not passed, will use arraysize property instead</li> </ul> <p></p>"},{"location":"reference/cursor/#fetchall","title":"fetchall","text":"<pre><code>@check_cursor_open\ndef fetchall() -&gt; list[RowType]\n</code></pre> <p>Fetch all remaining records from the current result set.  Returns empty list if no records remaining or result set is empty.</p> <p>Uses passed <code>row_factory</code> to cursor to determine <code>RowType</code> of returned rows.</p> <p></p>"},{"location":"reference/cursor/#close","title":"close","text":"<pre><code>def close() -&gt; None\n</code></pre> <p>Close cursor and cleanup resources</p> <p></p>"},{"location":"reference/cursor/#asynccursor","title":"AsyncCursor","text":"<pre><code>class AsyncCursor(BaseCursor[\"AsyncConnection\", RowType])\n</code></pre>"},{"location":"reference/cursor/#scroll_1","title":"scroll","text":"<pre><code>@acheck_cursor_open\nasync def scroll(value: int,\n                 *,\n                 mode: t.Literal[\"relative\", \"absolute\"] = \"relative\") -&gt; None\n</code></pre> <p>Move the cursor in the result set to a new position using the mode.</p> <p>If mode=<code>relative</code> (default), treat the passed value as an offset relative to the current position in the result set. If mode=<code>absolute</code>, move to the passed position.</p> <p>Arguments:</p> <ul> <li><code>value</code> - The offset if in <code>relative</code> mode; the target position if in <code>absolute</code> mode</li> <li><code>mode</code> - (optional) determines the model to use for the scroll.  Default: <code>relative</code></li> </ul> <p></p>"},{"location":"reference/cursor/#execute_1","title":"execute","text":"<pre><code>@acheck_cursor_open\nasync def execute(operation: str,\n                  params: dict | tuple | list | None = None,\n                  *,\n                  query_options: QueryOptions | None = None) -&gt; httpx.Response\n</code></pre> <p>Execute a query against the Pinot broker</p> <p>The query returns the <code>httpx.Response</code> from the request, which you normally will not need; however, it may be useful for debugging.</p> <p>Arguments:</p> <ul> <li><code>operation</code> - the sql operation to send to the broker</li> <li><code>params</code> - (optional) sql params to bind to the operation</li> <li><code>query_options</code> - (optional) query options that override what is set on cursor/connection</li> </ul> <p></p>"},{"location":"reference/cursor/#fetchone_1","title":"fetchone","text":"<pre><code>@acheck_cursor_open\nasync def fetchone() -&gt; RowType | None\n</code></pre> <p>Fetch the next record from the current result set or <code>None</code> if exhausted</p> <p>Uses passed <code>row_factory</code> to cursor to determine <code>RowType</code> of returned row</p> <p></p>"},{"location":"reference/cursor/#fetchmany_1","title":"fetchmany","text":"<pre><code>@acheck_cursor_open\nasync def fetchmany(size: int | None = None) -&gt; list[RowType]\n</code></pre> <p>Fetch the next size records from the current result set.  If size is not passed, the value of the <code>arraysize</code> property will be used instead.</p> <p>Uses passed <code>row_factory</code> to cursor to determine <code>RowType</code> of returned rows.</p> <p>This method can return fewer records than requested.  For example, if a size of 3 is passed, but the result set only has two records remaining, the two records will be returned only.</p> <p>Arguments:</p> <ul> <li><code>size</code> - (optional) number of records to fetch - if not passed, will use arraysize property instead</li> </ul> <p></p>"},{"location":"reference/cursor/#fetchall_1","title":"fetchall","text":"<pre><code>@acheck_cursor_open\nasync def fetchall() -&gt; list[RowType]\n</code></pre> <p>Fetch all remaining records from the current result set.  Returns empty list if no records remaining or result set is empty.</p> <p>Uses passed <code>row_factory</code> to cursor to determine <code>RowType</code> of returned rows.</p> <p></p>"},{"location":"reference/cursor/#close_1","title":"close","text":"<pre><code>async def close() -&gt; None\n</code></pre> <p>Close cursor and cleanup resources</p>"},{"location":"reference/exceptions/","title":"pinot_connect.exceptions","text":""},{"location":"reference/exceptions/#pinot_connectexceptions","title":"pinot_connect.exceptions","text":""},{"location":"reference/exceptions/#error","title":"Error","text":"<pre><code>class Error(Exception)\n</code></pre> <p>Exception that is the base class of all other error exceptions. You can use this to catch all errors with one single except statement.</p> <p></p>"},{"location":"reference/exceptions/#interfaceerror","title":"InterfaceError","text":"<pre><code>class InterfaceError(Error)\n</code></pre> <p>Exception raised for errors that are related to the database interface rather than the database itself</p> <p></p>"},{"location":"reference/exceptions/#databaseerror","title":"DatabaseError","text":"<pre><code>class DatabaseError(Error)\n</code></pre> <p>Exception raised for errors that are related to the database</p> <p></p>"},{"location":"reference/exceptions/#dataerror","title":"DataError","text":"<pre><code>class DataError(DatabaseError)\n</code></pre> <p>Exception raised for errors that are due to problems with the processed data like division by zero, numeric value out of range, etc</p> <p></p>"},{"location":"reference/exceptions/#operationalerror","title":"OperationalError","text":"<pre><code>class OperationalError(DatabaseError)\n</code></pre> <p>Exception raised for errors that are related to the database\u2019s operation and not necessarily under the control of the programmer, e.g. an unexpected disconnect occurs, the data source name is not found, a transaction could not be processed, a memory allocation error occurred during processing, etc</p> <p></p>"},{"location":"reference/exceptions/#internalerror","title":"InternalError","text":"<pre><code>class InternalError(DatabaseError)\n</code></pre> <p>Exception raised when the database encounters an internal error, e.g. the cursor is not valid anymore, the transaction is out of sync, etc</p> <p></p>"},{"location":"reference/exceptions/#programmingerror","title":"ProgrammingError","text":"<pre><code>class ProgrammingError(DatabaseError)\n</code></pre> <p>Exception raised for programming errors, e.g. table not found or already exists, syntax error in the SQL statement, wrong number of parameters specified, etc</p> <p></p>"},{"location":"reference/exceptions/#notsupportederror","title":"NotSupportedError","text":"<pre><code>class NotSupportedError(DatabaseError)\n</code></pre> <p>Exception raised in case a method or database API was used which is not supported by the database</p>"},{"location":"reference/options/","title":"pinot_connect.options","text":""},{"location":"reference/options/#pinot_connectoptions","title":"pinot_connect.options","text":""},{"location":"reference/options/#queryoptions","title":"QueryOptions","text":"<pre><code>@dataclass()\nclass QueryOptions()\n</code></pre> <p>Helper object for constructing query options for pinot</p> <p>All values are optional and default to being not set (will not be included in passed options)</p> <p>Attributes:</p> <ul> <li><code>timeout_ms</code> - timeout of query in milliseconds</li> <li><code>enable_null_handling</code> - enable advanced null handling</li> <li><code>explain_plan_verbose</code> - return verbose result for <code>EXPLAIN</code> query</li> <li><code>use_multi_stage_engine</code> - e multi-stage engine for executing query</li> <li><code>max_execution_threads</code> - Maximum threads to use to execute the query</li> <li><code>num_replica_groups_to_query</code> - When replica-group based routing is enabled, use it to query multiple replica-groups</li> <li><code>min_segment_group_trim_size</code> - Minimum groups to keep when trimming groups at the segment level for group-by queries</li> <li><code>min_server_group_trim_size</code> - Minimum groups to keep when trimming groups at the server level for group-by queries</li> <li><code>server_return_final_result</code> - For aggregation and group-by queries, ask servers to directly return final results   instead of intermediate results for aggregation</li> <li><code>server_return_final_result_key_unpartitioned</code> - For group-by queries, ask servers to directly return final results   instead of intermediate results for aggregations</li> <li><code>skip_indexes</code> - Which indexes to skip usage of (i.e. scan instead), per-column</li> <li><code>skip_upsert</code> - For upsert-enabled table, skip the effect of upsert and query all the records</li> <li><code>use_star_tree</code> - Useful to debug the star-tree index</li> <li><code>and_scan_reordering</code> - See description</li> <li><code>max_rows_in_join</code> - Configure maximum rows allowed in a join operation</li> <li><code>in_predicate_pre_sorted</code> - (Only apply to STRING columns) Indicates that the values in the IN clause is already   sorted, so that Pinot doesn't need to sort them again at query time</li> <li><code>in_predicate_lookup_algorithm</code> - The algorithm to use to look up the dictionary ids for the IN clause values</li> <li><code>max_server_response_size_bytes</code> - Long value config indicating the maximum length of the serialized response per   server for a query</li> <li><code>max_query_response_size_bytes</code> - Long value config indicating the maximum serialized response size across all   servers for a query</li> <li><code>filtered_aggregations_skip_empty_groups</code> - This config can be set to true to avoid computing all the groups in a   group by query with only filtered aggregations (and no non-filtered aggregations)</li> </ul> <p></p>"},{"location":"reference/options/#to_kv_pair","title":"to_kv_pair","text":"<pre><code>@classmethod\ndef to_kv_pair(cls, d: dict) -&gt; str\n</code></pre> <p>Pinot's servers expect query options to be sent as 'option1=value;option2=value</p> <p></p>"},{"location":"reference/options/#clientoptions","title":"ClientOptions","text":"<pre><code>@dataclasses.dataclass()\nclass ClientOptions()\n</code></pre> <p>Options too pass on to the underlying httpx Client/AsyncClient constructor</p> <p>Attributes:</p> <ul> <li><code>cookies</code> - (optional) Dictionary of Cookie items to include when sending requests</li> <li><code>verify</code> - (optional) Either <code>True</code> to use an SSL context with the default CA bundle, <code>False</code> to disable   verification, or an instance of <code>ssl.SSLContext</code> to use a custom context</li> <li><code>cert</code> - (optional) Path(s) to the SSL certificate file(s)</li> <li><code>trust_env</code> - (optional) Enables or disables usage of environment variables for configuration</li> <li><code>proxy</code> - (optional) A proxy URL where all the traffic should be routed</li> <li><code>timeout</code> - (optional) The timeout configuration to use when sending request, all in seconds</li> <li><code>follow_redirects</code> - (optional) Whether to follow redirects when sending request.  Default: <code>true</code>.</li> <li><code>limits</code> - (optional) The limits configuration to use.</li> <li><code>max_redirects</code> - (optional) The maximum number of redirect responses that should be followed request URLs</li> <li><code>transport</code> - (optional) A transport class to use for sending requests over the network</li> <li><code>event_hooks</code> - (optional) A list of hooks to when either request has been prepared or reponse has been fetched</li> <li><code>default_encoding</code> - (optional) The default encoding to use for decoding response text, if no charset information   is included in a response Content-Type header. Set to a callable for automatic character set detection.</li> <li><code>Default</code> - \"utf-8\".</li> </ul> <p></p>"},{"location":"reference/options/#requestoptions","title":"RequestOptions","text":"<pre><code>@dataclasses.dataclass()\nclass RequestOptions()\n</code></pre> <p>Options to pass to the actual HTTP request via execute methods</p> <p>Attributes:</p> <ul> <li><code>cookies</code> - (optional) Dictionary of Cookie items to include when sending requests</li> <li><code>timeout</code> - (optional) The timeout configuration to use when sending request, all in seconds</li> <li><code>extensions</code> - (optional) Optional dictionary for low-level request customizations</li> </ul>"},{"location":"reference/rows/","title":"pinot_connect.rows","text":""},{"location":"reference/rows/#pinot_connectrows","title":"pinot_connect.rows","text":""},{"location":"reference/rows/#rowmaker","title":"RowMaker","text":"<pre><code>class RowMaker(t.Protocol[RowType])\n</code></pre> <p>Protocol for a function that takes a list of values (a row) returned from the query and returns any RowType object</p> <p></p>"},{"location":"reference/rows/#rowfactory","title":"RowFactory","text":"<pre><code>class RowFactory(t.Protocol[RowType])\n</code></pre> <p>Protocol for a factory method that returns a RowMaker.  The method takes a description (from a cursor) which is often useful for building dictionaries for usage or for passing into other objects as kwargs</p> <p></p>"},{"location":"reference/rows/#tuple_row","title":"tuple_row","text":"<pre><code>def tuple_row(description: list[\"Column\"]) -&gt; RowMaker[tuple]\n</code></pre> <p>RowFactory that returns a tuple constructor to convert lis of values to tuple of values</p> <p>Returns: RowMaker[tuple[t.Any, ...]]</p> <p></p>"},{"location":"reference/rows/#list_row","title":"list_row","text":"<pre><code>def list_row(description: list[\"Column\"]) -&gt; RowMaker[list]\n</code></pre> <p>RowFactory that is a noop.  The data is returned as a list directly from the query, so this avoids any additional data conversion.  This is not the default as most dbapis return tuple rows, but can easily be used when wanted.</p> <p></p>"},{"location":"reference/rows/#dict_row","title":"dict_row","text":"<pre><code>def dict_row(description: list[\"Column\"]) -&gt; RowMaker[dict[str, t.Any]]\n</code></pre> <p>RowFactory that uses the description to get the column names and injects it into a row maker that converts a row to a dictionary</p> <p></p>"},{"location":"reference/rows/#dict_row_load_json_fields","title":"dict_row_load_json_fields","text":"<pre><code>def dict_row_load_json_fields(*fields: str) -&gt; RowFactory[dict[str, t.Any]]\n</code></pre> <p>pinot's query api always returns json fields as strings, with no indication that a field is actually a json field one way would be to make an additional request to get the metadata of the schema, however the other way that does not involve additional IO is specifying the lists of columns that should be loaded to python dictionaries and using orjson to do that as efficiently as possible.  This function takes the field names and for those fields, then calls orjson.loads on each of the corresponding values</p> <p></p>"},{"location":"reference/rows/#kwargs_row","title":"kwargs_row","text":"<pre><code>def kwargs_row(obj: t.Callable[..., T] | type[T]) -&gt; RowFactory[T]\n</code></pre> <p>RowFactory that uses the description to get the column names and builds a dictionary to be passed as kwargs. the kwargs are then passed into the passed function or type/model</p> <p></p>"},{"location":"reference/rows/#args_row","title":"args_row","text":"<pre><code>def args_row(obj: t.Callable[..., T] | type[T]) -&gt; RowFactory[T]\n</code></pre> <p>Row factory that unpacks the row into positional arguments to the passed function or type/model</p>"},{"location":"usage/","title":"Learn","text":"<p>Here are the basic resources you need to start using pinot_connect</p>"},{"location":"usage/basic/","title":"Basic Usage","text":"<p>This page describes the basic objects and methods in <code>pinot_connect</code> and how to use them.</p> <p>Cursors and connections are highly configurable.  While this page just describes basic usage, the  options tutorial and the options reference go into more detail.</p>"},{"location":"usage/basic/#connections","title":"Connections","text":"<p>The connection is the main entry point to using pinot_connect.  While connections can be constructed directly, you will  typically use <code>pinot_connect.connect</code> or <code>pinot_connect.AsyncConnection.connect</code> as it handles creating and configuring the <code>httpx</code>  client for you.</p> <p>Example</p> syncasync Using the connection factory<pre><code>import pinot_connect\n\n# use it as a context manager\nwith pinot_connect.connect(host=\"localhost\") as conn:\n    # pinot_connect.Connection\n\n# don't use it as a context manager, close it later\nconn = pinot_connect.connect(host=\"localhost\")\n# do stuff\nconn.close()\n</code></pre> Using the async connection factory<pre><code>import pinot_connect\n\nasync def main():\n    # use it as a context manaager\n    async with pinot_connect.AsyncConnection.connect(host=\"localhost) as conn:\n        # pinot_connect.AsyncConnection\n\n    # don't use it as a context manager, close it later\n    conn = await pinot_connect.AsyncConnection.connect(host=\"localhost\")\n    # do stuff\n    await conn.close()\n</code></pre> <ul> <li>Connections are designed to be reused.</li> <li>Unlike traditional database drivers, pinot_connect does not require a connection pool\u2014httpx handles this internally. In most    cases, a single connection per application is sufficient.</li> <li>The second request (and subsequent ones) will always be faster than the first, as <code>httpx</code> keeps the connection alive.</li> <li>Standard connections are thread-safe, while async connections are task-safe.</li> </ul> <p>Connection factories take the following arguments:</p> <ul> <li><code>host</code> - the hostname of your apache pinot broker</li> <li><code>port</code> - (optional) the port of your apache pinot broker, defaults to <code>8099</code></li> <li><code>username</code> - (optional): the username to use, if basic auth is enabled on the cluster</li> <li><code>password</code> - (optional): the password to use, if basic auth is enabled on the cluster</li> <li><code>scheme</code> - (optional): the scheme to use, defaults to <code>http</code>.  Must be one of <code>http</code> or <code>https</code>.  Additional    https configuration can be configured via <code>client_options</code>.</li> <li><code>database</code> - (optional): the database/tenant to use</li> <li><code>query_options</code> - (optional): global query options for all queries made from the connection. See query_options</li> <li><code>client_options</code> - (optional): httpx client options for all queries made from the connection. See client_options</li> </ul>"},{"location":"usage/basic/#cursors","title":"Cursors","text":"<p>Cursors are used for executing queries, scrolling through the result set, and fetching rows from the result set.  A cursor object can be constructed directly by passing a connection, however most of the time you will use the <code>cursor</code> factory function on <code>pinot_connect.Connection</code> or <code>pinot_connect.AsyncConnection</code>.</p> <p>Cursors support passing row factories.  See the row factory docs for detailed examples.</p> <p>The below examples assumes you already have a connection instance.</p> <p>Example</p> syncasync Using a Cursor<pre><code>from pinot_connect.rows import dict_row\n\n# use it as a context manager, cleans up resources when block exits\nwith conn.cursor(row_factory=dict_row) as cursor:\n    cursor.execute(\"select * from airlineStats\")\n    # fetch a single row from the result set\n    row = cursor.fetchone()  \n    # fetch the next ten rows from the result set\n    next_ten_rows = cursor.fetchmany(10) \n    # fetch remaining rows\n    remaining_rows = cursor.fetchall() \n\n# or call it and close it later\ncursor = conn.cursor(row_factory=dict_row)\n# do stuff\ncursor.close()\n</code></pre> Using an AsyncCursor<pre><code>async def main(conn: pinot_connect.AsyncConnection):\n    # use it as an async context manager, cleans up rsesources when block exits\n    async with conn.cursor(row_factory=dict_row):\n        await cursor.execute(\"select * from airlineStats\")\n        # fetch a single row from the result set\n        rows = await cursor.fetchone()  \n        # fetch the next ten rows from the result seet\n        next_ten_rows = await cursor.fetchmany(10) \n         # fetch remaining rows\n        remaining_rows = await cursor.fetchall()\n\n    # or await it and close it later\n    cursor = await conn.cursor(row_factory=dict_row)\n    # do stuff\n    await cursor.close()\n</code></pre> <ul> <li>Cursors, like connections, can be reused. Executing a new query automatically clears the cursor\u2019s state, allowing you    to fetch results from the latest execution.</li> <li>Cursors are NOT thread-safe or task-safe. Sharing them across threads or async tasks can cause race conditions. Each    thread or task should create and manage its own cursor.</li> <li>Creating a cursor is lightweight, so creating a new one when needed is recommended.</li> </ul> <p>Cursor factories take the following arguments: - <code>query_options</code> - (optional): query options to be used by cursor, overrides any options set at connection level.  See query_options. - <code>row_factory</code> - (optional): RowFactory type to use to build rows fetched from cursor, defaults to returning tuples.</p>"},{"location":"usage/basic/#parameters","title":"Parameters","text":"<p>Pinot does not support server-side parameter binding, but <code>pinot_connect</code> simplifies query composition while ensuring type  safety by handling client-side parameter binding. It converts Python types into Pinot-compatible formats and ensures  they are safely serialized to JSON for query requests.</p> <p><code>pinot_connect</code> supports the <code>pyformat</code> paramstyle, allowing:</p> <ul> <li>Named parameters: Use <code>%(name)s</code>, with parameters passed as a dict</li> <li>Positional parameters: Use <code>%s</code>, with parameters passed as a list or tuple</li> </ul> select * from airlineStats where Airtime &gt; 200 and Carrier = 'AA'<pre><code>cursor.execute(\n    \"select * from airlineStats where AirTime &gt; %s and Carrier = %s\", \n    (200, \"AA\")\n)\n</code></pre> <p>Below is a table of input types and how they will be interpolated into the query string:</p> Input Type Example Input Output Example Notes <code>str</code> <code>\"hello\"</code> <code>\"'hello'\"</code> Escapes single quotes within strings. <code>str</code> (with single quote) <code>\"O'Reilly\"</code> <code>\"'O''Reilly'\"</code> Escapes single quotes by doubling them. <code>bool</code> <code>True</code> / <code>False</code> <code>\"TRUE\"</code> / <code>\"FALSE\"</code> Converts booleans to uppercase SQL literals. <code>int</code> <code>42</code> <code>\"42\"</code> Converts integers to strings. <code>float</code> <code>3.14</code> <code>\"3.14\"</code> Converts floats to strings. <code>decimal.Decimal</code> <code>Decimal('10.5')</code> <code>\"10.5\"</code> Converts Decimal values to strings. <code>datetime.date</code> <code>date(2025, 2, 24)</code> <code>\"'2025-02-24'\"</code> Uses ISO format inside single quotes. <code>datetime.datetime</code> <code>datetime(2025, 2, 24, 14, 30, 0)</code> <code>\"'2025-02-24T14:30:00'\"</code> Uses ISO format inside single quotes. <code>list</code>, <code>tuple</code>, <code>set</code> <code>[1, 'abc', None]</code> <code>\"(1, 'abc', NULL)\"</code> Recursively applies escaping for each element. <code>NoneType</code> <code>None</code> <code>\"NULL\"</code> Converts <code>None</code> to SQL <code>NULL</code>. <code>dict</code> <code>{\"key\": \"value\"}</code> <code>\"'{\"key\":\"value\"}'\"</code> JSON-encodes the dictionary and escapes single quotes. <code>uuid.UUID</code> <code>UUID(\"12345678-1234-5678-1234-567812345678\")</code> <code>\"'12345678-1234-5678-1234-567812345678'\"</code> Converts UUID to string and wraps in single quotes. Unsupported types <code>object()</code> Raises <code>ProgrammingError</code> Only supported types are listed above."},{"location":"usage/basic/#cursormogrify","title":"<code>cursor.mogrify</code>","text":"<p><code>cursor.mogrify</code> can be used for binding a query once and reusing it in subsequent execute calls, but is also useful for debugging Using cursor.mogrify<pre><code>bound_op = cursor.mogrify(\n    \"select * from airlineStats where AirTime &gt; %s\", \n    (200,)\n)\nprint(bound_op)  # \"select * from airlineStats where AirTime &gt; 200\n</code></pre></p>"},{"location":"usage/basic/#converting-types","title":"Converting types","text":"<p>When querying data, <code>pinot_connect</code> will convert Pinot types into python types where it can.  </p> <p>Warning</p> <p>JSON columns are both STRING type and serialized as strings in json when querying Pinot.  Because of this, it is impossible to know which columns are JSON without using a row_factory.  If you want your JSON columns deserialized into python dictionaries, you should use the <code>dict_row_load_json_fields</code> row factory, or write your own row factory.</p> Pinot Type Python Type Notes <code>INT</code> <code>int</code> <code>LONG</code> <code>int</code> <code>FLOAT</code> <code>float</code> <code>DOUBLE</code> <code>float</code> <code>BIG_DECIMAL</code> <code>decimal.Decimal</code> <code>BOOLEAN</code> <code>bool</code> <code>TIMESTAMP</code> <code>datetime.datetime</code> uses the <code>ciso8601</code> package <code>STRING</code> <code>str</code> <code>JSON</code> <code>str</code> Can be loaded with <code>dict_row_load_json_fields</code> <code>BYTES</code> <code>str</code> Pinot returns bytes columns as encoded strings, so for performance reasons <code>pinot_connect</code> leaves those untouched"},{"location":"usage/options/","title":"Advanced Configuration Options","text":"<p>pinot_connect has two helper objects for advanced configuration of the <code>httx</code> client as well as Apache Pinot query options</p>"},{"location":"usage/options/#queryoptions","title":"QueryOptions","text":"<p>Helper object for building Apache Pinot  query options.</p> <p>Query options can be set at different levels: connection, cursor, and execute.</p> <ul> <li><code>QueryOptions</code> set on the connection serve as defaults.</li> <li><code>QueryOptions</code> set on the cursor override those from the connection but inherit any not explicitly set.</li> <li><code>QueryOptions</code> set on execute override those from the cursor but inherit any not explicitly set.</li> <li>Any unset option will use the Pinot server default</li> </ul> Using QueryOptions<pre><code>import pinot_connect\n\nquery = \"select * from airlineStats limit 10\"\n\n# set default query timeout on connection to 500ms\nwith pinot_connect.connect(\"localhost\", query_options=pinot_connect.QueryOptions(timeout_ms=500)) as conn:\n    # cursor default is 500, inherited from connection\n    with conn.cursor() as cursor:  \n        # uses timeout of 500ms, inherited from cursor, which inherited from connection\n        cursor.execute(query)\n        # use a timeout of 100ms for this query only\n        cursor.execute(query, query_options=pinot_connect.QueryOptions(timeout_ms=100))\n\n    # now the default for this cursor will be 150, overrides connection default of 500ms\n    with conn.cursor(query_options=pinot_connect.QueryOptions(timeout_ms=150)): \n        # uses timeout of 150ms, inherited from cursor\n        cursor.execute(query)\n        # use a timeout of 50ms for this query only\n        cursor.execute(query, query_options=pinot_connect.QueryOptions(timeout_ms=50))\n</code></pre> <p>Note</p> <p><code>timeout_ms</code> is only a measure of actual query execution, which DOES NOT include network latency.  To set a timeout on execution time + network latency, see <code>ClientOptions</code> below.</p>"},{"location":"usage/options/#clientoptions","title":"ClientOptions","text":"<p>Helper object for building keyword arguments to pass from  <code>pinot_connect.Connection</code> -&gt; <code>httpx.Client</code> and <code>AsyncConnection</code>  -&gt; <code>httpx.AsyncClient</code>.  Because queries are emitted to Apache Pinot via http/https, this object allows you to customize additional settings for all requests made from the <code>pinot_connect.Connection</code>/<code>pinot_connect.AsyncConnection</code> instance(s).</p> <p>Note</p> <p><code>timeout</code> in <code>httpx</code> accepts seconds, but takes a float value.  This is different than pinot's options, which takes <code>timeout_ms</code> as milliseconds.</p> Using ClientOptions<pre><code>import pinot_connect\n\nquery = \"select * from airlineStats limit 10\"\n\n# set default request timeout on all requests from connection to 2s\nwith pinot_connect.connect(\"localhost\", client_options=pinot_connect.ClientOptions(timeout=2)) as conn:\n    with conn.cursor() as cursor:  \n        cursor.execute(query)\n</code></pre>"},{"location":"usage/options/#requestoptions","title":"RequestOptions","text":"<p>Helper object for setting timeouts, cookies or extensions for a single request/query.  The passed timeout and/or cookies would override anything set on the connection and/or cursor.</p> Using RequestOptions<pre><code>import pinot_connect\n\nquery = \"select * from airlineStats limit 10\"\n\n# set default request timeout on all requests from connection to 2s\nwith pinot_connect.connect(\"localhost\", client_options=pinot_connect.ClientOptions(timeout=2.0)) as conn:\n    with conn.cursor() as cursor:  \n        # extend timeout for this query only\n        cursor.execute(query, request_options=pinot_connect.RequestOptions(timeout=5.0))\n        # uses timeout of 2.0 from connection\n        cursor.execute(query)\n</code></pre>"},{"location":"usage/row_factories/","title":"Row Factories","text":""},{"location":"usage/row_factories/#introduction","title":"Introduction","text":"<p>Row factories are a feature in <code>pinot_connect</code> that allow users to customize the format of query results. By default, query  results are returned as tuples.  They are heavily inspired by a feature with the same name in psycopg.   pinot_connect  ships with a handful of userful row factories, but it is also easy to define your own.  Row factories are typed with  generics and typevars to ensure static type checkers (such as mypy) will correctly check the return types.</p> <p>Warning</p> <p>Because Apache Pinot's query protocol is http/https and the data is returned via json, data is serialized from the server as a list of lists.  Using a <code>list_row</code> factory gives the best performance, because it does not modify the  data.  The default, though, is <code>tuple_row</code> to maintain DB-API compliance.  The performance penalty is small, but it  can add up on large result sets.</p>"},{"location":"usage/row_factories/#how-row-factories-work","title":"How Row Factories Work","text":"<p>Internally, row factories work by processing each row of the query result set and transforming it into the desired  format before being returned to the user. This transformation is achieved through user-defined functions or callable  objects that serve as the \"factory\" for producing rows.  These transformations are done lazily and guarantees each row is only ever processed exactly once. Some common use cases include:</p> <ul> <li>Returning rows as dictionaries</li> <li>Returning rows as a user defined object, such as a dataclass or pydantic model</li> <li>Passing the row as kwargs or args to a function </li> <li>Loading json strings returned from pinot into python objects (since pinot always returns them as strings over the api)</li> </ul> <p>This functionality ensures that users have full control over the structure and format of their query results.</p>"},{"location":"usage/row_factories/#examples","title":"Examples","text":""},{"location":"usage/row_factories/#built-in-row-factories","title":"Built in row factories","text":"<p>All examples assume the below code has been ran first</p> <pre><code>import dataclasses\nfrom typing import Self\n\nimport pinot_connect\nfrom pinot_connect import rows\n\nconnection = pinot_connect.connect(host=\"localhost\")\n</code></pre> tuple_row | list_row | dict_rowkwargs_rowargs_rowdict_row_load_json_fields tuple_row<pre><code>with conn.cursor() as cursor:  # do not have to pass, tuple_row is default\n    cursor.execute(\"select * from airlineStats limit 10\")\n    print(type(cursor.fetchone())  # tuple\n</code></pre> dict_row<pre><code>with conn.cursor(row_factory=rows.dict_row) as cursor:\n    cursor.execute(\"select * from airlineStats limit 10\")\n    print(type(cursor.fetchone())  # dict\n</code></pre> list_row<pre><code>with conn.cursor(row_factory=rows.list_row) as cursor:\n    cursor.execute(\"select * from airlineStats limit 10)\n    print(type(cursor.fetchone()) # list\n</code></pre> Using an object<pre><code>@dataclass.dataclass\nclass AirTime:\n    AirTime: int\n    AirlineID: int\n\nwith conn.cursor(row_factory=rows.kwargs_row(AirTime)) as cursor:\n    cursor.execute(\"select AirTime, AirLineID from airlineStats limit 10\")\n    print(type(cursor.fetchone))  # AirTime\n</code></pre> Using a function<pre><code>@dataclass.dataclass\nclass AirTime:\n    air_time: int\n    air_line_id: int\n\n    @classmethod\n    def from_row(cls, **row) -&gt; Self:\n        return cls(air_time=row['AirTime'], air_line_id=row['AirlineID'])\n\nwith conn.cursor(row_factory=rows.kwargs_row(AirTime.from_row)):\n    cursor.execute(\"select AirTime, AirLineID from airlineStats limit 10\")\n    print(type(cursor.fetchone)) # AirTime\n</code></pre> Using an object<pre><code>class AirTime:\n    def __init__(air_time: int, air_line_id: int):\n        self.air_time = air_time\n        self.air_line_id = air_line_id\n\n# rows.kwargs_row -&gt; RowFactory[AirTime]\nwith conn.cursor(row_factory=rows.args_row(AirTime)) as cursor:\n    cursor.execute(\"select * from airlineStats limit 10\")\n    print(type(cursor.fetchone))  # AirTime\n</code></pre> Using a function<pre><code>def print_and_return(*args) -&gt; tuple:\n    print(args)\n    return args\n\nwith conn.cursor(row_factory=rows.args_row(print_and_return)):\n    cursor.execute(\"select * from airlineStats limit 10\")\n    print(type(cursor.fetchone)) # tuple\n</code></pre> <p>Info</p> <p>Over the API Pinot returns JSON columns as strings, and also indicates the column type as a string.  Often time, you will want to serialize the json columns to python objects.  This row factory handles doing that efficiently and returning the fields as values in a dict row; in other row factories, the value will always be a string.</p> <pre><code>with conn.cursor(row_factory=rows.dict_row_load_json_fields(\"actor\", \"payload\"):\n    cursor.execute(\"select actor, payload, id from githubEvents limit 10\")\n    row = cursor.fetchone()\n    print(type(row['actor']))  # dict\n    print(type(row['payload'])) # dict\n</code></pre>"},{"location":"usage/row_factories/#writing-your-own-row-factories","title":"Writing your own row factories","text":"<p>It is simple to write your own row factories - when doing so, it is important to use the types defined in <code>pinot_connect.rows</code> to ensure correct static typing.</p> <ul> <li><code>RowType</code> when the type is determined by something passed to an outer function, such as <code>pinot_connect.rows.kwargs_row</code>.   When doing this, you should also make sure the outer function returns <code>RowFactory[RowType]</code></li> <li><code>RowMaker</code> should be returned from every <code>RowFactory</code> function.</li> </ul> <p>Let's look at how you might write your own factory that always validates a row with pydantic.  This example assume that you have pydantic already installed.</p> <pre><code>import pydantic\nfrom pinot_connect.rows import RowMaker\nfrom pinot_connect import Column\nfrom typing import Iterator\n\nclass AirlineStats(pydantic.BaseModel):\n    air_time: int = pydantic.Field(..., alias=\"AirTime\")\n    air_line_id: int = pydantic.Field(..., alias=\"AirlineID\")\n\ndef airline_stats_row(description: list[Column]) -&gt; RowMaker[AirlineStats]:\n    # important to do this at top level of the function so we only have to build column names once per query\n    column_names = [i[0] for i in description]\n\n    def airline_stats_row_(values: Iterator) -&gt; AirlineStats:\n        data = dict(zip(column_names, values))\n        return AirlineStats(**data)\n\n    return airline_stats_row_\n\nwith connection.cursor(row_factory=airline_stats_row) as cursor:\n    cursor.execute(\"select * from airlineStats limit 10\")\n    print(type(cursor.fetchone()))  # AirlineStats\n</code></pre>"}]}